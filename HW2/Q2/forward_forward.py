# -*- coding: utf-8 -*-
"""Forward-Forward.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KrJPZEDXKRKr9A9w5GqUcdJW-7lB9uOB
"""

import torch
import torchvision
from torchvision import transforms
from torch.utils.data import DataLoader
import torch.nn as nn
from tqdm import tqdm

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using {device} device")

# Define data transformations for MNIST
transform = transforms.Compose([
    transforms.ToTensor(),  # Convert images to PyTorch tensors
    transforms.Normalize((0.5,), (0.5,)),  # Normalize pixel values to the range [-1, 1]
    transforms.Lambda(lambda x: x.view(-1))
])

# Load the MNIST dataset
train_dataset = torchvision.datasets.MNIST(
    root='./data',  # Specify the directory to save the dataset
    train=True,  # Load the training dataset
    transform=transform,  # Apply transformations
    download=True  # Download the dataset if not available locally
)

test_dataset = torchvision.datasets.MNIST(
    root='./data',
    train=False,  # Load the test dataset
    transform=transform,
    download=True
)

# Create data loaders to manage the datasets
batch_size = 64
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# Check the dataset sizes
print(f"Number of training examples: {len(train_dataset)}")
print(f"Number of test examples: {len(test_dataset)}")

# Define a function to convert labels to one-hot vectors
one_hot_encode = nn.functional.one_hot

# Generate incorrect labels for data
num_classes = 10  # MNIST has 10 classes

# generators
def set_label(data, label, num_classes = 10):
        N = data.shape[0]
        _data = data.clone()
        _data[:, 0:num_classes] = 0.0
        _data[:, label] = 1
        return _data

def pos_data_gen(data, targets, num_classes = 10):
        _data = data.clone()
        _data[:, 0:num_classes] = 0.0
        _data[range(_data.shape[0]), targets] = 1
        return _data

def neg_data_gen(data, targets, num_classes = 10):
        # get random label for each data
        rand_target = torch.randint(0, num_classes, (len(targets),), dtype=torch.int64)
        _data = data.clone()
        _data[:, 0:num_classes] = 0.0
        _data[range(_data.shape[0]), rand_target] = 1
        return _data

for data, target in train_loader:
    # Convert labels to one-hot vectors
    neg_x = neg_data_gen(data, target)
    pos_x = pos_data_gen(data, target)
    change_label = set_label(data, 2)

    # Check the shapes of one-hot labels
    print("Shape of pos data:", pos_x.shape)
    print("Shape of neg data:", neg_x.shape)
    print("Shape of changed labels:", change_label.shape)
    break

class Layer(nn.Linear):
    def __init__(self, input_size, output_size, threshold, epochs=50, lr=0.01,
                 optimizer='Adam', device='cpu', dtype=torch.float32):
        super(Layer, self).__init__(input_size, output_size, device=device)
        self.threshold = threshold
        self.epochs = epochs
        self.activation = nn.ReLU()

        # Set the optimizer based on the input
        if optimizer == 'Adam':
            self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)
        elif optimizer == 'SGD':
            self.optimizer = torch.optim.SGD(self.parameters(), lr=lr)
        else:
            self.optimizer = optimizer # provided by user

        # Move the layer to the specified device and set the dtype
        self.to(device=device, dtype=dtype)

    def forward(self, X, X_neg = None):
        # forward path
        if X_neg is None:
          X1 = X / (X.norm(2, 1, keepdim=True) + 1e-5)
          y = self.activation(super(Layer, self).forward(X1))
          return y
        # training the layer
        X_pos = X
        for _ in range(self.epochs):
            loss = self.loss(X_pos, X_neg)
            # optimization
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()

        return self.forward(X_pos).detach(), self.forward(X_neg).detach()

    @staticmethod
    def goodness(y):
        return torch.mean(torch.square(self.activation(y.clone())), dim=1).view(-1)

    def loss(self, pos_data, neg_data):
        pos_goodness = Layer.goodness(self.forward(pos_data)) - self.threshold
        neg_goodness = Layer.goodness(self.forward(neg_data)) - self.threshold
        # Cross-entropy loss
        loss = torch.log(
            1 + torch.exp(
                torch.cat([-pos_goodness, neg_goodness])
              )
        ).mean()

        return loss

# Test
input_size = 20
output_size = 10
threshold = 5
dtype=torch.float64

# Create an instance of the Layer with custom settings
layer = Layer(input_size, output_size, threshold, epochs=100, lr=0.1, optimizer='Adam', device=device, dtype=dtype)

# Generate example data (simplified)
positive_data = torch.rand(1, input_size).to(device=device, dtype=dtype)  # Example positive data
negative_data = torch.rand(1, input_size).to(device=device, dtype=dtype)  # Example negative data

# Training pass
output_pos, output_neg = layer.forward(positive_data, negative_data)

# Default forward pass
output_default = layer.forward(positive_data)
goodness = layer.goodness(output_default)
neg_goodness = layer.goodness(output_neg)

print("Default Forward Output:", output_default)
print("Default Forward Goodness:", goodness, " Negative data goodness:", neg_goodness)
print("Output for positive data after training:", output_pos)
print("Output for negative data after training:", output_neg)

class Supervised_NLayerNetwork(nn.Module):
    def __init__(self, layer_sizes, num_classes, threshold, epochs=100, lr=0.01, optimizer='Adam', device='cpu', dtype=torch.float32):
        super(Supervised_NLayerNetwork, self).__init__()

        self.num_classes = num_classes

        self.layers = nn.ModuleList([
            Layer(layer_sizes[i], layer_sizes[i+1], threshold, epochs=epochs, lr=lr, optimizer=optimizer, device=device, dtype=dtype)
            for i in range(len(layer_sizes)-1)
        ])

    def forward(self, X, X_neg=None):
        if X_neg is None:
            goodness = []
            X_ = X
            for i in range(self.num_classes):
              g = []
              X = set_label(X_, i, self.num_classes)
              for layer in self.layers:
                  X = layer(X)
                  g.append(Layer.goodness(X))
              goodness.append(sum(g).unsqueeze(1))
            goodness = torch.cat(goodness, 1)
            return goodness # optional, can use softmax, can use argmax
        else:
            for layer in self.layers:
                X, X_neg = layer(X, X_neg)
            return X, X_neg

d = 28 * 28
threshold = 2
supervised_model = Supervised_NLayerNetwork([d, 256, 512], num_classes, threshold, device=device, lr=0.01, epochs=50)

supervised_model

"""### Training"""

cache = {'positive': [], 'negative': []}

for (data, targets) in tqdm(train_loader):
    x_pos = pos_data_gen(data, targets).to(device)
    x_neg = neg_data_gen(data, targets).to(device)
    x_pos, x_neg = supervised_model(x_pos, x_neg)
    cache['positive'].append(Layer.goodness(x_pos).mean())
    cache['negative'].append(Layer.goodness(x_neg).mean())

# Plotting
import matplotlib.pyplot as plt
plt.title('Goodness metric')
plt.xlabel('Epoch')
for key, data in cache.items():
    # Convert CUDA tensors to CPU before converting to NumPy
    data_numpy = [val.cpu().numpy() for val in data]
    plt.plot(data_numpy, '-o', label="%s data" % key)

plt.axhline(y=threshold, color='r', linestyle='--', label='Threshold')

plt.legend(loc='lower center', ncol=4)
plt.show()

train_corrects, train_total = 0, 0
with torch.no_grad():
  for data, targets in tqdm(train_loader):
      outputs = supervised_model(data.to(device))
      predicted = torch.argmax(outputs, 1)
      train_corrects += (predicted == targets.to(device)).sum().item()
      train_total += targets.size(0)

test_corrects, test_total = 0, 0
with torch.no_grad():
  for data, targets in tqdm(test_loader):
      outputs = supervised_model(data.to(device))
      predicted = torch.argmax(outputs, 1)
      test_corrects += (predicted == targets.to(device)).sum().item()
      test_total += targets.size(0)

train_accuracy = (train_corrects / train_total) * 100
test_accuracy = (test_corrects / test_total) * 100

print('\nTrain Accuracy: {:.2f}%'.format(train_accuracy))
print('Test Accuracy: {:.2f}%'.format(test_accuracy))

"""## Unsupervised"""

import torch.nn.functional as F

def create_mask(image_size):
    mask = torch.randint(0, 2, image_size, dtype=torch.float32)

    # Apply a series of dilations and erosions
    for _ in range(3):
        mask = F.avg_pool2d(mask.unsqueeze(0).unsqueeze(0), kernel_size=3, stride=1, padding=1).squeeze()

    mask[mask > 0.5] = 1
    mask[mask <= 0.5] = 0

    return mask, 1 - mask

import matplotlib.pyplot as plt

image_size = (28, 28)
mask1, mask2 = create_mask(image_size)

# Plot the masks
plt.subplot(1, 2, 1)
plt.imshow(mask1, cmap='gray')
plt.title('Mask 1')

plt.subplot(1, 2, 2)
plt.imshow(mask2, cmap='gray')
plt.title('Mask 2')

plt.show()

def hybrid_data(data, image_size):
    _data = data.clone()

    # Shuffle the rows
    perm = torch.randperm(_data.shape[0])
    permuted_tensor = _data[perm]

    # Create random masks
    mask1, mask2 = create_mask(image_size)

    # Apply masks to create hybrid data
    hybrid_data = mask1.view(-1) * _data + mask2.view(-1) * permuted_tensor

    return hybrid_data

image_size = (28, 28)

for (data, _) in train_loader:
    x_pos = data.to(device)
    x_neg = hybrid_data(data, image_size).to(device)
    # Plot the data
    for i in range(3):
      plt.subplot(1, 2, 1)
      plt.imshow(x_pos.cpu()[i, :].reshape(image_size), cmap='gray')
      plt.title('positive data')
      plt.subplot(1, 2, 2)
      plt.imshow(x_neg.cpu()[i, :].reshape(image_size), cmap='gray')
      plt.title('negative data')
      plt.show()
    break

class Unsupervised_NLayerNetwork(nn.Module):
    def __init__(self, layer_sizes, threshold, epochs=100, lr=0.01, optimizer='Adam', device='cpu', dtype=torch.float32):
        super(Unsupervised_NLayerNetwork, self).__init__()

        self.layers = nn.ModuleList([
            Layer(layer_sizes[i], layer_sizes[i+1], threshold, epochs=epochs, lr=lr, optimizer=optimizer, device=device, dtype=dtype)
            for i in range(len(layer_sizes)-1)
        ])

    def forward(self, X, X_neg=None):
        X_pos = X.clone()
        if X_neg is not None:
          X_neg = X_neg.clone()
          for  layer in self.layers:
              X_pos, X_neg = layer(X_pos, X_neg)
          return X_pos, X_neg
        else:
          # Initialize an empty list to store the tensors
          concatenated_tensors = []

          for  layer in self.layers:
              X_pos = layer.forward(X_pos)
              concatenated_tensors.append(X_pos)

          cached_layers_ouputs = torch.cat(concatenated_tensors, dim=1)
          return cached_layers_ouputs

"""### Train unsupervised network"""

d = 28 * 28
threshold = 2
unsupervised_model = Unsupervised_NLayerNetwork([d, 256, 512], threshold, device=device, lr=0.01, epochs=50)

unsupervised_model

cache = {'positive': [], 'negative': []}
image_size = (28, 28)

for (data, _) in tqdm(train_loader):
    x_pos = data.to(device)
    x_neg = hybrid_data(data, image_size).to(device)
    x_pos, x_neg = unsupervised_model(x_pos, x_neg)
    cache['positive'].append(Layer.goodness(x_pos).mean())
    cache['negative'].append(Layer.goodness(x_neg).mean())

# Plotting
import matplotlib.pyplot as plt
plt.title('Goodness metric')
plt.xlabel('Epoch')
for key, data in cache.items():
    # Convert CUDA tensors to CPU before converting to NumPy
    data_numpy = [val.cpu().numpy() for val in data]
    plt.plot(data_numpy, '-o', label="%s data" % key)

plt.axhline(y=threshold, color='r', linestyle='--', label='Threshold')

plt.legend(loc='lower center', ncol=4)
plt.show()

# Freeze the parameters of the unsupervised model
for param in unsupervised_model.parameters():
    param.requires_grad = False

learned_representations = None

unsupervised_model.eval() # set to inference mode
with torch.no_grad():
    for data, labels in train_loader:
        learned_representations = unsupervised_model(data.to(device))
        neg_representation = unsupervised_model(hybrid_data(data, image_size).to(device))
        print("represtation map shape: ", learned_representations.shape)

        # Sort the learned representations by label
        sorted_representations, sorted_labels = zip(*sorted(zip(learned_representations.cpu().numpy(), labels.cpu().numpy()), key=lambda x: x[1]))
        sorted_representations = torch.tensor(sorted_representations)
        sorted_labels = torch.tensor(sorted_labels)

        # Plot the sorted representations
        plt.figure(figsize=(12, 6))
        plt.subplot(1, 2, 1)
        plt.imshow(sorted_representations.T, cmap='hot', aspect='auto')
        plt.title('Learned Representations (Sorted by Label)')
        plt.xlabel('Batch Index')
        plt.ylabel('Feature Index')

        # Draw lines to indicate different labels on the x-axis
        unique_labels = sorted_labels.unique()
        for label in unique_labels[:-1]:
            label_indices = (sorted_labels == label).nonzero(as_tuple=True)[0]
            plt.axvline(label_indices[-1].item() + 0.5, color='white', linestyle='--', linewidth=1)

        # Plot the negative representations
        plt.subplot(1, 2, 2)
        plt.imshow(neg_representation.cpu().numpy(), cmap='hot', aspect='auto')
        plt.title('Negative Data Representations')
        plt.xlabel('Batch Index')
        plt.ylabel('Feature Index')
        plt.show()

        break  # Only using one batch for illustration

# Define Linear Classifier, if we want to change later
class LinearClassifier(nn.Module):
    def __init__(self, input_size, num_classes, encoder):
        super(LinearClassifier, self).__init__()
        self.fc = nn.Linear(input_size, num_classes)
        self.encoder = encoder

    def forward(self, x):
        z = self.encoder(x)
        return torch.softmax(self.fc(z), dim=1)

# Define and train the linear classifier
classifier = LinearClassifier(
    input_size=learned_representations.size(-1),
    num_classes=num_classes,
    encoder = unsupervised_model
)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(classifier.parameters(), lr=0.01)

# Train the linear classifier

num_epochs = 10
for epoch in range(num_epochs):
    classifier.train()
    for data, labels in tqdm(train_loader, desc=f"Epoch {epoch + 1}/{num_epochs}"):
        # Forward pass
        outputs = classifier(data)

        # Compute the loss
        loss = criterion(outputs, labels)

        # Backward and optimize
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

train_corrects, train_total = 0, 0

classifier.eval()

with torch.no_grad():
  for data, targets in tqdm(train_loader):
      outputs = classifier(data.to(device))
      predicted = torch.argmax(outputs, 1)
      train_corrects += (predicted == targets.to(device)).sum().item()
      train_total += targets.size(0)

test_corrects, test_total = 0, 0
with torch.no_grad():
  for data, targets in tqdm(test_loader):
      outputs = classifier(data.to(device))
      predicted = torch.argmax(outputs, 1)
      test_corrects += (predicted == targets.to(device)).sum().item()
      test_total += targets.size(0)

train_accuracy = (train_corrects / train_total) * 100
test_accuracy = (test_corrects / test_total) * 100

print('\nTrain Accuracy: {:.2f}%'.format(train_accuracy))
print('Test Accuracy: {:.2f}%'.format(test_accuracy))